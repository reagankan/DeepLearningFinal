{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction Baselines\n",
    "---\n",
    "ROC AUC and Average Precision computed on YouTube dataset using these link prediction baselines:\n",
    "1. Adamic-Adar\n",
    "2. Jaccard Coefficient\n",
    "3. Preferential Attachment\n",
    "4. Resource Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in Graph Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EGO_USER = 0 # which ego network to look at\n",
    "\n",
    "def read_data_file_as_csr_matrix(filename):\n",
    "    data = pd.read_csv(filename, sep=' ', header=None, dtype=np.uint32, error_bad_lines = False)\n",
    "    rows = data[0]\n",
    "    cols = data[1]\n",
    "    ones = np.ones(len(rows), np.uint32)\n",
    "    matrix = sp.csr_matrix((ones, (rows, cols)))\n",
    "    print(matrix)\n",
    "    return matrix\n",
    "\n",
    "# Load pickled (adj, feat) tuple\n",
    "network_dir = './youtube-data/080327_3.txt_train.txt'\n",
    "# adj2 = read_data_file_as_csr_matrix(network_dir)\n",
    "\n",
    "g = nx.Graph()\n",
    "\n",
    "with open(network_dir, 'r') as f:\n",
    "    for node_connect in f.readlines():\n",
    "        node_connect = node_connect.replace('\\n', '')\n",
    "        node_connect = node_connect.split(\" \")\n",
    "        node_connect[0] = int(node_connect[0])\n",
    "        node_connect[1] = int(node_connect[1])\n",
    "        g.add_edge(node_connect[0], node_connect[1])\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# draw network\n",
    "# nx.draw_networkx(g, with_labels=False, node_size=1, node_color='r')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing/Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: not enough removable edges to perform full train-test split!\n",
      "Num. (test, val) edges requested: ( 1258 ,  419 )\n",
      "Num. (test, val) edges returned: ( 537 ,  0 )\n"
     ]
    }
   ],
   "source": [
    "from gae.preprocessing import mask_test_edges\n",
    "np.random.seed(0) # make sure train-test split is consistent between notebooks\n",
    "adj_sparse = nx.to_scipy_sparse_matrix(g)\n",
    "\n",
    "# Perform train-test split\n",
    "adj_train, train_edges, train_edges_false, val_edges, val_edges_false, \\\n",
    "    test_edges, test_edges_false = mask_test_edges(adj_sparse, test_frac=.3, val_frac=.1)\n",
    "g_train = nx.from_scipy_sparse_matrix(adj_train) # new graph object with only non-hidden edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes: 3949\n",
      "Total edges: 4194\n",
      "Training edges (positive): 3657\n",
      "Training edges (negative): 3657\n",
      "Validation edges (positive): 0\n",
      "Validation edges (negative): 419\n",
      "Test edges (positive): 537\n",
      "Test edges (negative): 1258\n"
     ]
    }
   ],
   "source": [
    "# Inspect train/test split\n",
    "print(\"Total nodes:\", adj_sparse.shape[0])\n",
    "print(\"Total edges:\", int(adj_sparse.nnz/2)) # adj is symmetric, so nnz (num non-zero) = 2*num_edges)\n",
    "print(\"Training edges (positive):\", len(train_edges))\n",
    "print(\"Training edges (negative):\", len(train_edges_false))\n",
    "print(\"Validation edges (positive):\", len(val_edges))\n",
    "print(\"Validation edges (negative):\", len(val_edges_false))\n",
    "print(\"Test edges (positive):\", len(test_edges))\n",
    "print(\"Test edges (negative):\", len(test_edges_false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc_score(edges_pos, edges_neg, score_matrix):\n",
    "    # Store positive edge predictions, actual values\n",
    "    preds_pos = []\n",
    "    pos = []\n",
    "    for edge in edges_pos:\n",
    "        preds_pos.append(score_matrix[edge[0], edge[1]]) # predicted score\n",
    "        pos.append(adj_sparse[edge[0], edge[1]]) # actual value (1 for positive)\n",
    "        \n",
    "    # Store negative edge predictions, actual values\n",
    "    preds_neg = []\n",
    "    neg = []\n",
    "    for edge in edges_neg:\n",
    "        preds_neg.append(score_matrix[edge[0], edge[1]]) # predicted score\n",
    "        neg.append(adj_sparse[edge[0], edge[1]]) # actual value (0 for negative)\n",
    "        \n",
    "    # Calculate scores\n",
    "    preds_all = np.hstack([preds_pos, preds_neg])\n",
    "    labels_all = np.hstack([np.ones(len(preds_pos)), np.zeros(len(preds_neg))])\n",
    "    roc_score = roc_auc_score(labels_all, preds_all)\n",
    "    ap_score = average_precision_score(labels_all, preds_all)\n",
    "    return roc_score, ap_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adamic-Adar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Adamic-Adar indexes from g_train\n",
    "import time\n",
    "start_time = time.time()\n",
    "aa_matrix = np.zeros(adj_sparse.shape)\n",
    "for u, v, p in nx.adamic_adar_index(g_train): # (u, v) = node indices, p = Adamic-Adar index\n",
    "    aa_matrix[u][v] = p\n",
    "    aa_matrix[v][u] = p # make sure it's symmetric\n",
    "    \n",
    "# Normalize array\n",
    "aa_matrix = aa_matrix / aa_matrix.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adamic-Adar Test ROC score:  0.6041157819008625\n",
      "Adamic-Adar Test AP score:  0.4430262260870411\n",
      "Time taken: 94.47 sec\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROC AUC and Average Precision\n",
    "aa_roc, aa_ap = get_roc_score(test_edges, test_edges_false, aa_matrix)\n",
    "calc_time = round(time.time() - start_time, 2)\n",
    "print('Adamic-Adar Test ROC score: ', str(aa_roc))\n",
    "print('Adamic-Adar Test AP score: ', str(aa_ap))\n",
    "print('Time taken: {} sec'.format(calc_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Jaccard Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute Jaccard Coefficients from g_train\n",
    "jc_matrix = np.zeros(adj_sparse.shape)\n",
    "start_time = time.time()\n",
    "for u, v, p in nx.jaccard_coefficient(g_train): # (u, v) = node indices, p = Jaccard coefficient\n",
    "    jc_matrix[u][v] = p\n",
    "    jc_matrix[v][u] = p # make sure it's symmetric\n",
    "    \n",
    "# Normalize array\n",
    "jc_matrix = jc_matrix / jc_matrix.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Coefficient Test ROC score:  0.6039270456786067\n",
      "Jaccard Coefficient Test AP score:  0.4347536417524206\n",
      "Time taken: 124.52 sec\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROC AUC and Average Precision\n",
    "jc_roc, jc_ap = get_roc_score(test_edges, test_edges_false, jc_matrix)\n",
    "calc_time = round(time.time() - start_time, 2)\n",
    "print('Jaccard Coefficient Test ROC score: ', str(jc_roc))\n",
    "print('Jaccard Coefficient Test AP score: ', str(jc_ap))\n",
    "print('Time taken: {} sec'.format(calc_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preferential Attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate, store Adamic-Index scores in array\n",
    "pa_matrix = np.zeros(adj_sparse.shape)\n",
    "start_time = time.time()\n",
    "for u, v, p in nx.preferential_attachment(g_train): # (u, v) = node indices, p = Jaccard coefficient\n",
    "    pa_matrix[u][v] = p\n",
    "    pa_matrix[v][u] = p # make sure it's symmetric\n",
    "    \n",
    "# Normalize array\n",
    "pa_matrix = pa_matrix / pa_matrix.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preferential Attachment Test ROC score:  0.8608606963848503\n",
      "Preferential Attachment Test AP score:  0.6532588653931537\n",
      "Time taken: 52.89 sec\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROC AUC and Average Precision\n",
    "pa_roc, pa_ap = get_roc_score(test_edges, test_edges_false, pa_matrix)\n",
    "calc_time = round(time.time() - start_time, 2)\n",
    "print('Preferential Attachment Test ROC score: ', str(pa_roc))\n",
    "print('Preferential Attachment Test AP score: ', str(pa_ap))\n",
    "print('Time taken: {} sec'.format(calc_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Common Neighbors\n",
    "\n",
    "For common neighbors, we would explore two different variations of common neighbors. However, it is omitted because we do not have 'community' information as that would require separate evaluation techniques.\n",
    "\n",
    "1. Ratio of within- and inter-cluster common neighbors of all node pairs in ebunch.\n",
    "2. Count the number of common neighbors of all node pairs in ebunch using community information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Resource Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate, store Adamic-Index scores in array\n",
    "ra_matrix = np.zeros(adj_sparse.shape)\n",
    "start_time = time.time()\n",
    "for u, v, p in nx.resource_allocation_index(g_train): # (u, v) = node indices, p = Jaccard coefficient\n",
    "    ra_matrix[u][v] = p\n",
    "    ra_matrix[v][u] = p # make sure it's symmetric\n",
    "    \n",
    "# Normalize array\n",
    "ra_matrix /= ra_matrix.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource Allocation Test ROC score:  0.6041157819008625\n",
      "Resource Allocation Test AP score:  0.4430262260870411\n",
      "Time taken: 85.62 sec\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROC AUC and Average Precision\n",
    "ra_roc, ra_ap = get_roc_score(test_edges, test_edges_false, ra_matrix)\n",
    "calc_time = round(time.time() - start_time, 2)\n",
    "print('Resource Allocation Test ROC score: ', str(ra_roc))\n",
    "print('Resource Allocation Test AP score: ', str(ra_ap))\n",
    "print('Time taken: {} sec'.format(calc_time)) # this was 9.71s before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
