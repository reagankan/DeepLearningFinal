{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# node2vec\n",
    "---\n",
    "[node2vec](http://snap.stanford.edu/node2vec/) for link prediction:\n",
    "1. Perform train-test split\n",
    "1. Train skip-gram model on random walks within training graph\n",
    "2. Get node embeddings from skip-gram model\n",
    "3. Create bootstrapped edge embeddings by taking the Hadamard product of node embeddings\n",
    "4. Train a logistic regression classifier on these edge embeddings (possible edge --> edge score between 0-1)\n",
    "5. Evaluate these edge embeddings on the validation and test edge sets\n",
    "\n",
    "node2vec source code: https://github.com/aditya-grover/node2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in Graph Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import pickle\n",
    "import node2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/jeremykke/anaconda3/lib/python3.7/site-packages (3.8.2)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/jeremykke/anaconda3/lib/python3.7/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/jeremykke/anaconda3/lib/python3.7/site-packages (from gensim) (1.17.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/jeremykke/anaconda3/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/jeremykke/anaconda3/lib/python3.7/site-packages (from gensim) (2.0.0)\n",
      "Requirement already satisfied: boto3 in /home/jeremykke/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.12.49)\n",
      "Requirement already satisfied: boto in /home/jeremykke/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: requests in /home/jeremykke/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.49 in /home/jeremykke/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.15.49)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/jeremykke/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/jeremykke/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.5)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/jeremykke/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/jeremykke/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jeremykke/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/jeremykke/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.2)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/jeremykke/anaconda3/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.49->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/jeremykke/anaconda3/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.49->boto3->smart-open>=1.8.1->gensim) (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.txt  0302  080327txt_test.txt  080327txt_train.txt  1.txt  2.txt  log.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "\n",
    "with open('sccedges.txt', 'r') as f:\n",
    "    net = f.readlines()\n",
    "    n_lines = len(net)\n",
    "\n",
    "ajm = []\n",
    "    \n",
    "for i in range(3,n_lines//30):\n",
    "    elem = net[i].rstrip().split(\"\\t\") #1. strip 'return', 2. split\n",
    "        #print(len(elem))\n",
    "        #print(net[i].rstrip())\n",
    "        #print(elem)\n",
    "        #print(len(elem))\n",
    "    src = elem[0]\n",
    "    dst = elem[1]\n",
    "    link = (src, dst)\n",
    "    ajm.append(link)\n",
    "    \n",
    "g = nx.Graph(ajm) # re-create graph using node indices (0 to num_nodes-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw network\n",
    "nx.draw_networkx(g, with_labels=False, node_size=50, node_color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing/Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gae.preprocessing import mask_test_edges\n",
    "np.random.seed(0) # make sure train-test split is consistent between notebooks\n",
    "adj_sparse = nx.to_scipy_sparse_matrix(g)\n",
    "\n",
    "# Perform train-test split\n",
    "adj_train, train_edges, train_edges_false, val_edges, val_edges_false, \\\n",
    "    test_edges, test_edges_false = mask_test_edges(adj_sparse, test_frac=.3, val_frac=.1)\n",
    "g_train = nx.from_scipy_sparse_matrix(adj_train) # new graph object with only non-hidden edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect train/test split\n",
    "print(\"Total nodes:\", adj_sparse.shape[0])\n",
    "print(\"Total edges:\", int(adj_sparse.nnz/2)) # adj is symmetric, so nnz (num non-zero) = 2*num_edges\n",
    "print(\"Training edges (positive):\", len(train_edges))\n",
    "print(\"Training edges (negative):\", len(train_edges_false))\n",
    "print(\"Validation edges (positive):\", len(val_edges))\n",
    "print(\"Validation edges (negative):\", len(val_edges_false))\n",
    "print(\"Test edges (positive):\", len(test_edges))\n",
    "print(\"Test edges (negative):\", len(test_edges_false))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train node2vec (Learn Node Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import node2vec\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node2vec settings\n",
    "# NOTE: When p = q = 1, this is equivalent to DeepWalk\n",
    "\n",
    "P = 1 # Return hyperparameter\n",
    "Q = 1 # In-out hyperparameter\n",
    "WINDOW_SIZE = 10 # Context size for optimization\n",
    "NUM_WALKS = 10 # Number of walks per source\n",
    "WALK_LENGTH = 80 # Length of walk per source\n",
    "DIMENSIONS = 128 # Embedding dimension\n",
    "DIRECTED = False # Graph directed/undirected\n",
    "WORKERS = 8 # Num. parallel workers\n",
    "ITER = 1 # SGD epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing, generate walks\n",
    "g_n2v = node2vec.Graph(g_train, DIRECTED, P, Q) # create node2vec graph instance\n",
    "g_n2v.preprocess_transition_probs()\n",
    "walks = g_n2v.simulate_walks(NUM_WALKS, WALK_LENGTH)\n",
    "walks = [map(str, walk) for walk in walks]\n",
    "\n",
    "# Train skip-gram model\n",
    "model = Word2Vec(walks, size=32, window=7, min_count=0, sg=1, workers=1, iter=ITER)\n",
    "\n",
    "# Store embeddings mapping\n",
    "emb_mappings = model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Edge Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create node embeddings matrix (rows = nodes, columns = embedding features)\n",
    "emb_list = []\n",
    "for node_index in range(0, adj_sparse.shape[0]):\n",
    "    node_str = str(node_index)\n",
    "    node_emb = emb_mappings[node_str]\n",
    "    emb_list.append(node_emb)\n",
    "emb_matrix = np.vstack(emb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate bootstrapped edge embeddings (as is done in node2vec paper)\n",
    "    # Edge embedding for (v1, v2) = hadamard product of node embeddings for v1, v2\n",
    "def get_edge_embeddings(edge_list):\n",
    "    embs = []\n",
    "    for edge in edge_list:\n",
    "        node1 = edge[0]\n",
    "        node2 = edge[1]\n",
    "        emb1 = emb_matrix[node1]\n",
    "        emb2 = emb_matrix[node2]\n",
    "        edge_emb = np.multiply(emb1, emb2)\n",
    "        embs.append(edge_emb)\n",
    "    embs = np.array(embs)\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-set edge embeddings\n",
    "pos_train_edge_embs = get_edge_embeddings(train_edges)\n",
    "neg_train_edge_embs = get_edge_embeddings(train_edges_false)\n",
    "train_edge_embs = np.concatenate([pos_train_edge_embs, neg_train_edge_embs])\n",
    "\n",
    "# Create train-set edge labels: 1 = real edge, 0 = false edge\n",
    "train_edge_labels = np.concatenate([np.ones(len(train_edges)), np.zeros(len(train_edges_false))])\n",
    "\n",
    "# Val-set edge embeddings, labels\n",
    "pos_val_edge_embs = get_edge_embeddings(val_edges)\n",
    "neg_val_edge_embs = get_edge_embeddings(val_edges_false)\n",
    "val_edge_embs = np.concatenate([pos_val_edge_embs, neg_val_edge_embs])\n",
    "val_edge_labels = np.concatenate([np.ones(len(val_edges)), np.zeros(len(val_edges_false))])\n",
    "\n",
    "# Test-set edge embeddings, labels\n",
    "pos_test_edge_embs = get_edge_embeddings(test_edges)\n",
    "neg_test_edge_embs = get_edge_embeddings(test_edges_false)\n",
    "test_edge_embs = np.concatenate([pos_test_edge_embs, neg_test_edge_embs])\n",
    "\n",
    "# Create val-set edge labels: 1 = real edge, 0 = false edge\n",
    "test_edge_labels = np.concatenate([np.ones(len(test_edges)), np.zeros(len(test_edges_false))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Edge Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression classifier on train-set edge embeddings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "edge_classifier = LogisticRegression(random_state=0)\n",
    "edge_classifier.fit(train_edge_embs, train_edge_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted edge scores: probability of being of class \"1\" (real edge)\n",
    "val_preds = edge_classifier.predict_proba(val_edge_embs)[:, 1]\n",
    "val_roc = roc_auc_score(val_edge_labels, val_preds)\n",
    "val_ap = average_precision_score(val_edge_labels, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted edge scores: probability of being of class \"1\" (real edge)\n",
    "test_preds = edge_classifier.predict_proba(test_edge_embs)[:, 1]\n",
    "test_roc = roc_auc_score(test_edge_labels, test_preds)\n",
    "test_ap = average_precision_score(test_edge_labels, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'node2vec Validation ROC score: ', str(val_roc)\n",
    "print 'node2vec Validation AP score: ', str(val_ap)\n",
    "print 'node2vec Test ROC score: ', str(test_roc)\n",
    "print 'node2vec Test AP score: ', str(test_ap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
